# OpenAIì˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ íŒ¨í‚¤ì§€
from langchain_openai import OpenAIEmbeddings
# ChromaDBë¥¼ LangChainê³¼ ì—°ë™í•˜ëŠ” íŒ¨í‚¤ì§€ 
from langchain.vectorstores import Chroma
# ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ì œê³µí•˜ëŠ” ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ í¬í•¨í•˜ëŠ” íŒ¨í‚¤ì§€
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.document_loaders import DirectoryLoader, TextLoader
# OpenAI API í‚¤ ë¡œë“œ
import openai
import os
from dotenv import load_dotenv


# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# API key ì„¤ì •
openai.api_key = os.getenv("OPENAI_API_KEY")


def build_vector_store():
    '''
    ë²¡í„° DB ìƒì„± í•¨ìˆ˜: RAGë¥¼ êµ¬ì¶•í•˜ëŠ” ì‹œì ê³¼ RAGë¥¼ ì‚¬ìš©í•˜ëŠ” ì‹œì ì„ ë¶„ë¦¬ (âœ… LLM ì‚¬ìš© ì „ í•œ ë²ˆë§Œ ì‹¤í–‰í•˜ê¸°)
    txt_folder í´ë” í•˜ì˜ ëª¨ë“  txt íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ì²­í‚¹ê³¼ ì„ë² ë”© í›„ ë²¡í„° DBí™” í•œë‹¤.
    '''
    try:
        # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ì¶œë ¥
        current_dir = os.getcwd()
        print(f"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {current_dir}")
        
        # í…ìŠ¤íŠ¸ íŒŒì¼ í´ë” ê²½ë¡œ í™•ì¸
        txt_folder = os.path.join(current_dir, "txt_folder")
        print(f"í…ìŠ¤íŠ¸ íŒŒì¼ í´ë” ê²½ë¡œ: {txt_folder}")
        
        # ë²¡í„° ìŠ¤í† ì–´ ì €ì¥ ê²½ë¡œ í™•ì¸
        vector_store_path = os.path.join(current_dir, "vector_store")
        print(f"ë²¡í„° ìŠ¤í† ì–´ ì €ì¥ ê²½ë¡œ: {vector_store_path}")
        
        # 1. ë¬¸ì„œ ë¶ˆëŸ¬ì˜¤ê¸° (txt_folder í•˜ì˜ ì¹´í…Œê³ ë¦¬ë³„ txt)
        loader = DirectoryLoader(txt_folder, glob="*.txt", loader_cls=TextLoader)
        docs = loader.load()
        print(f"ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(docs)}")

        # 2. ë¬¸ì„œ chunking í•˜ê¸°
        # chunk_size: ì¥ì†Œ í•˜ë‚˜ + ì¼ë¶€ ì¶”ê°€ ì •ë³´ í¬í•¨ 700, chunk_overlap: ì²­í¬ ê°„ì— ì¤‘ìš”í•œ ì •ë³´ê°€ ëŠì–´ì§€ì§€ ì•Šë„ë¡ ì˜¤ë²„ë© ì‚¬ì´ì¦ˆëŠ” 350ìœ¼ë¡œ ì„¤ì •
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=350)
        splits = text_splitter.split_documents(docs)
        print(f"ì²­í¬ ìˆ˜: {len(splits)}")

        # 3. embedding ë„êµ¬ ì„¤ì •
        embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")
            
        # 4. Chroma ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ë° ì €ì¥
        vector_store = Chroma.from_documents(
            documents=splits,
            embedding=embeddings,
            persist_directory=vector_store_path  # ë²¡í„° ìŠ¤í† ì–´ ì €ì¥ ê²½ë¡œ
        )
        
        # ì €ì¥ í™•ì¸
        print(f"\nğŸ“‚ ë²¡í„° ìŠ¤í† ì–´ ë¬¸ì„œ ìˆ˜: {vector_store._collection.count()}")
        print(f"ğŸ“‚ ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ ê²½ë¡œ: {vector_store._persist_directory}")
        
    except Exception as e:
        print(f"ì—ëŸ¬ ë°œìƒ: {str(e)}")
        

# í•´ë‹¹ ìŠ¤í¬ë¦½íŠ¸(.py íŒŒì¼)ê°€ ì§ì ‘ ì‹¤í–‰ë  ë•Œë§Œ build_vector_store() í•¨ìˆ˜ë¥¼ ì‹¤í–‰
if __name__ == "__main__":
    '''
    ì´ íŒŒì¼ì´ ë…ë¦½ì ì¸ ì‹¤í–‰ íŒŒì¼ë¡œ ì‹¤í–‰ë  ë•Œë§Œ build_vector_store()ë¥¼ ì‹¤í–‰í•˜ê³ ,
    ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ importë  ë•ŒëŠ” ì‹¤í–‰ë˜ì§€ ì•ŠëŠ”ë‹¤.
    '''
    build_vector_store()
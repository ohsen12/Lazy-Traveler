from langchain.prompts import ChatPromptTemplate, PromptTemplate
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain.chains import LLMChain
import openai
import os
from dotenv import load_dotenv
from .models import ChatHistory
from django.conf import settings
from datetime import datetime
from django.contrib.auth import get_user_model

User = get_user_model()

persist_dir = os.path.join(settings.BASE_DIR, 'vector_store')

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

embeddings = OpenAIEmbeddings()
vector_store = Chroma(
    persist_directory=persist_dir,  
    embedding_function=embeddings  
)

retriever = vector_store.as_retriever(search_kwargs={"k": 5})

llm = ChatOpenAI(model="gpt-4o-mini")

# âœ… ì¿¼ë¦¬ íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ìš© LLM + í”„ë¡¬í”„íŠ¸ ì²´ì¸
query_transform_prompt = PromptTemplate.from_template("""
ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë²¡í„° ê²€ìƒ‰ì„ ìœ„í•œ ìµœì í™” ì¿¼ë¦¬ë¡œ ë³€í™˜í•˜ì„¸ìš”.  
ì‚¬ìš©ìì˜ ìœ„ì¹˜ì™€ ê´€ì‹¬ íƒœê·¸ë¥¼ ê³ ë ¤í•´ ê°„ê²°í•˜ê³  í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.

ğŸ”¹ ì‚¬ìš©ì ì§ˆë¬¸: {user_query}  
ğŸ”¹ ìœ„ì¹˜ ì •ë³´: {location_context}  
ğŸ”¹ ê´€ì‹¬ íƒœê·¸: {tags_context}

ğŸ‘‰ ìµœì í™”ëœ ê²€ìƒ‰ ì¿¼ë¦¬:
""")

query_transform_chain = LLMChain(llm=ChatOpenAI(model="gpt-3.5-turbo"), prompt=query_transform_prompt)


# ëŒ€í™” ë‚´ì—­ ê°€ì ¸ì˜¤ê¸°
def get_context(session_id, max_turns=5):
    chat_history = ChatHistory.objects.filter(session_id=session_id).order_by("-created_at")[:max_turns]
    return "\n\n".join([f"User: {chat.message}\nBot: {chat.response}" for chat in reversed(chat_history)])


# ìœ ì € íƒœê·¸ ê°€ì ¸ì˜¤ê¸°
def get_user_tags(username):
    try:
        user = User.objects.get(username=username)  
        tags = user.tags.split(",") if user.tags else []
        return tags
    except User.DoesNotExist:
        return []


# âœ… Query Transformation â†’ ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
def retriever_invoke(user_query, location_context, tags_context):
    try:
        # 1ï¸âƒ£ ì¿¼ë¦¬ ë³€í™˜ ìˆ˜í–‰
        transformed_query = query_transform_chain.predict(
            user_query=user_query,
            location_context=location_context,
            tags_context=tags_context
        )
        print(f"ğŸ”§ ë³€í™˜ëœ ê²€ìƒ‰ ì¿¼ë¦¬: {transformed_query}")

        # 2ï¸âƒ£ ë³€í™˜ëœ ì¿¼ë¦¬ë¡œ ë²¡í„° ê²€ìƒ‰
        docs = retriever.invoke(transformed_query)
        return docs

    except Exception as e:
        print(f"âŒ ì¿¼ë¦¬ ë³€í™˜ ë° ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        return []


# í”„ë¡¬í”„íŠ¸ ì •ì˜
prompt = ChatPromptTemplate.from_template(
"""
ë‹¹ì‹ ì€ ì§€ì—­ ê¸°ë°˜ ë§›ì§‘ê³¼ ê´€ê´‘ì§€ë¥¼ ì¶”ì²œí•˜ëŠ” ì „ë¬¸ AI ì±—ë´‡ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì´í•´í•˜ê³ , ë²¡í„° DBì—ì„œ ê²€ìƒ‰í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” 4ì‹œê°„ì§œë¦¬ ì¼ì •ì„ ì œê³µí•©ë‹ˆë‹¤.

ğŸ”¹ **ë‹µë³€ ê·œì¹™**
1. **ì •í™•í•œ ì •ë³´ë§Œ ì œê³µ**: ë²¡í„° DBì—ì„œ ì°¾ì€ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
2. **ì‚¬ìš©ìì˜ í˜„ì¬ ìœ„ì¹˜ ê³ ë ¤**:  
   {location_context}
3. **í˜„ì¬ ì‹œê°„ ê¸°ë°˜ ì¶”ì²œ (ì´ 4ì‹œê°„ ì¼ì • êµ¬ì„±)**:  
   {time_context}

ğŸ” **ì‚¬ìš©ì ì§ˆë¬¸**  
{question}

ğŸ—‚ **ì°¸ê³ í•  ì •ë³´ (ë²¡í„° DB ê²€ìƒ‰ ê²°ê³¼ ë° ëŒ€í™” ë‚´ì—­)**  
{context}

ğŸ“Œ ë§Œì•½ ë²¡í„° DBì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•˜ë©´, ë‹¤ìŒê³¼ ê°™ì´ ì‘ë‹µí•˜ì„¸ìš”:  
âŒ "í˜„ì¬ í•´ë‹¹ ì§€ì—­ì˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¥ì†Œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”!"

**ğŸ“… 4ì‹œê°„ì§œë¦¬ ì¶”ì²œ ì¼ì •**:
1ï¸âƒ£ **{time_context} ì‹œì‘ (ì²« ì¥ì†Œ)**  
2ï¸âƒ£ ë‹¤ìŒ ì¥ì†Œ  
3ï¸âƒ£ ë§ˆë¬´ë¦¬ ì¥ì†Œ
"""
)


# âœ… ë©”ì¸ ì¶”ì²œ í•¨ìˆ˜
def get_recommendation(user_query, session_id=None, username=None, latitude=None, longitude=None):
    try:
        now = datetime.now()
        current_hour = now.hour
        current_time = now.strftime("%Y-%m-%d %H:%M:%S")

        time_of_day = "ì˜¤ì „" if current_hour < 12 else "ì˜¤í›„" if current_hour < 18 else "ì €ë…"

        if latitude is None or longitude is None:
            latitude, longitude = 37.5704, 126.9831

        user_tags = get_user_tags(username)
        tags_query = " OR ".join(user_tags) if user_tags else ""

        print(f"ğŸ” í˜„ì¬ ì„¸ì…˜ ID: {session_id}")
        print(f"ğŸ” ì‚¬ìš©ìëª…: {username}")
        print(f"ğŸ“ ìœ„ì¹˜: ìœ„ë„ {latitude}, ê²½ë„ {longitude}")
        print(f"ğŸ” ë²¡í„° ìŠ¤í† ì–´ ê²½ë¡œ: {persist_dir}")
        print(f"ğŸ” ë²¡í„° ìŠ¤í† ì–´ ë¬¸ì„œ ìˆ˜: {vector_store._collection.count()}")
        print(f"ğŸ” ì‚¬ìš©ì íƒœê·¸: {user_tags}")

        location_context = f"ìœ„ë„ {latitude}, ê²½ë„ {longitude}" if latitude and longitude else "ìœ„ì¹˜ ì •ë³´ ì—†ìŒ"
        time_context = f"{current_time}, {time_of_day}"
        tags_context = f"{', '.join(user_tags)}" if user_tags else "ê´€ì‹¬ì‚¬ ì •ë³´ ì—†ìŒ"

        # ëŒ€í™” ë‚´ì—­ ê°€ì ¸ì˜¤ê¸°
        context = get_context(session_id)

        # âœ… ë²¡í„° ê²€ìƒ‰ â†’ ì¿¼ë¦¬ íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ í›„ ê²€ìƒ‰
        docs = retriever_invoke(
            user_query=user_query,
            location_context=location_context,
            tags_context=tags_context
        )
        print(f"ğŸ” ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}")

        if not docs:
            return "âŒ ê´€ë ¨ ì¥ì†Œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¥ì†Œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”."

        # ê²€ìƒ‰ ê²°ê³¼ + ëŒ€í™” ë‚´ì—­ í†µí•©
        context += f"\n{location_context}\n{time_context}\n{tags_context}\n"
        context += "\n".join([doc.page_content for doc in docs])

        # LLM ì²´ì¸ ì‹¤í–‰
        chain = prompt | llm

        result = chain.invoke({
            "context": context,
            "location_context": location_context,
            "time_context": time_context,
            "question": user_query
        })

        result_content = result.content
        print("ğŸ¤– ìµœì¢… ì‘ë‹µ:\n", result_content)

        return result_content

    except Exception as e:
        print(f"âŒ ì¶”ì²œ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return f"ì¶”ì²œ ìƒì„± ì˜¤ë¥˜: {str(e)}"
